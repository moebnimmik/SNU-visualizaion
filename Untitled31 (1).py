{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1af4754-1a1d-43a9-a45a-3aa1d335935c",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalHashError",
     "evalue": "module '__main__' has no attribute '__file__'\n\nWhile caching the body of `load_data()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function load_data at 0x14f294540>\n```\n\nPlease see the `hash_funcs` [documentation](https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/streamlit/runtime/legacy_caching/hashing.py:360\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# Hash the input\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (tname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_bytes(obj, context))\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# call to_bytes inside _to_bytes things get double-counted.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/streamlit/runtime/legacy_caching/hashing.py:623\u001b[0m, in \u001b[0;36m_CodeHasher._to_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_should_be_hashed(code\u001b[38;5;241m.\u001b[39mco_filename):\n\u001b[1;32m    624\u001b[0m     context \u001b[38;5;241m=\u001b[39m _get_context(obj)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/streamlit/runtime/legacy_caching/hashing.py:402\u001b[0m, in \u001b[0;36m_CodeHasher._file_should_be_hashed\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_is_in_folder_glob(\n\u001b[0;32m--> 402\u001b[0m     filepath, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_main_script_directory()\n\u001b[1;32m    403\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_in_pythonpath(filepath)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/streamlit/runtime/legacy_caching/hashing.py:710\u001b[0m, in \u001b[0;36m_CodeHasher._get_main_script_directory\u001b[0;34m()\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;66;03m# This works because we set __main__.__file__ to the\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# script path in ScriptRunner.\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m abs_main_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(__main__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(abs_main_path\u001b[38;5;241m.\u001b[39mparent)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module '__main__' has no attribute '__file__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalHashError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;129m@st\u001b[39m\u001b[38;5;241m.\u001b[39mcache\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m():\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(CSV_FILE_PATH)\n\u001b[0;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m load_data()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Streamlit 앱 제목\u001b[39;00m\n\u001b[1;32m     16\u001b[0m st\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCHD ETF Companies by Sector\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/streamlit/runtime/legacy_caching/caching.py:709\u001b[0m, in \u001b[0;36mcache.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_spinner:\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m spinner(message, _cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 709\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m get_or_create_cached_value()\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_or_create_cached_value()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/streamlit/runtime/legacy_caching/caching.py:631\u001b[0m, in \u001b[0;36mcache.<locals>.wrapped_func.<locals>.get_or_create_cached_value\u001b[0;34m()\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m cache_key\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# Delay generating the cache key until the first call.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;66;03m# This way we can see values of globals, including functions\u001b[39;00m\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# defined after this one.\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# If we generated the key earlier we would only hash those\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;66;03m# globals by name, and miss changes in their code or value.\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m     cache_key \u001b[38;5;241m=\u001b[39m _hash_func(non_optional_func, hash_funcs)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;66;03m# First, get the cache that's attached to this function.\u001b[39;00m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;66;03m# This cache's key is generated (above) from the function's code.\u001b[39;00m\n\u001b[1;32m    635\u001b[0m mem_cache \u001b[38;5;241m=\u001b[39m _mem_caches\u001b[38;5;241m.\u001b[39mget_cache(cache_key, max_entries, ttl)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/streamlit/runtime/legacy_caching/caching.py:761\u001b[0m, in \u001b[0;36m_hash_func\u001b[0;34m(func, hash_funcs)\u001b[0m\n\u001b[1;32m    750\u001b[0m update_hash(\n\u001b[1;32m    751\u001b[0m     (func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m),\n\u001b[1;32m    752\u001b[0m     hasher\u001b[38;5;241m=\u001b[39mfunc_hasher,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    755\u001b[0m     hash_source\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    756\u001b[0m )\n\u001b[1;32m    758\u001b[0m \u001b[38;5;66;03m# Include the function's body in the hash. We *do* pass hash_funcs here,\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;66;03m# because this step will be hashing any objects referenced in the function\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;66;03m# body.\u001b[39;00m\n\u001b[0;32m--> 761\u001b[0m update_hash(\n\u001b[1;32m    762\u001b[0m     func,\n\u001b[1;32m    763\u001b[0m     hasher\u001b[38;5;241m=\u001b[39mfunc_hasher,\n\u001b[1;32m    764\u001b[0m     hash_funcs\u001b[38;5;241m=\u001b[39mhash_funcs,\n\u001b[1;32m    765\u001b[0m     hash_reason\u001b[38;5;241m=\u001b[39mHashReason\u001b[38;5;241m.\u001b[39mCACHING_FUNC_BODY,\n\u001b[1;32m    766\u001b[0m     hash_source\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    767\u001b[0m )\n\u001b[1;32m    768\u001b[0m cache_key \u001b[38;5;241m=\u001b[39m func_hasher\u001b[38;5;241m.\u001b[39mhexdigest()\n\u001b[1;32m    769\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmem_cache key for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, cache_key\n\u001b[1;32m    771\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/streamlit/runtime/legacy_caching/hashing.py:108\u001b[0m, in \u001b[0;36mupdate_hash\u001b[0;34m(val, hasher, hash_reason, hash_source, context, hash_funcs)\u001b[0m\n\u001b[1;32m    105\u001b[0m hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mhash_source \u001b[38;5;241m=\u001b[39m hash_source\n\u001b[1;32m    107\u001b[0m ch \u001b[38;5;241m=\u001b[39m _CodeHasher(hash_funcs)\n\u001b[0;32m--> 108\u001b[0m ch\u001b[38;5;241m.\u001b[39mupdate(hasher, val, context)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/streamlit/runtime/legacy_caching/hashing.py:385\u001b[0m, in \u001b[0;36m_CodeHasher.update\u001b[0;34m(self, hasher, obj, context)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, hasher, obj: Any, context: Context \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update the provided hasher with the hash of an object.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_bytes(obj, context)\n\u001b[1;32m    386\u001b[0m     hasher\u001b[38;5;241m.\u001b[39mupdate(b)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/streamlit/runtime/legacy_caching/hashing.py:374\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InternalHashError(ex, obj)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# In case an UnhashableTypeError (or other) error is thrown, clean up the\u001b[39;00m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# stack so we don't get false positives in future hashing calls\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/streamlit/runtime/legacy_caching/hashing.py:360\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    356\u001b[0m hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mpush(obj)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# Hash the input\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (tname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_bytes(obj, context))\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# call to_bytes inside _to_bytes things get double-counted.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mgetsizeof(b)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/streamlit/runtime/legacy_caching/hashing.py:623\u001b[0m, in \u001b[0;36m_CodeHasher._to_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    621\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__code__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_should_be_hashed(code\u001b[38;5;241m.\u001b[39mco_filename):\n\u001b[1;32m    624\u001b[0m     context \u001b[38;5;241m=\u001b[39m _get_context(obj)\n\u001b[1;32m    625\u001b[0m     defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__defaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/streamlit/runtime/legacy_caching/hashing.py:402\u001b[0m, in \u001b[0;36m_CodeHasher._file_should_be_hashed\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_is_blacklisted:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_is_in_folder_glob(\n\u001b[0;32m--> 402\u001b[0m     filepath, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_main_script_directory()\n\u001b[1;32m    403\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_in_pythonpath(filepath)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/streamlit/runtime/legacy_caching/hashing.py:710\u001b[0m, in \u001b[0;36m_CodeHasher._get_main_script_directory\u001b[0;34m()\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m__main__\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;66;03m# This works because we set __main__.__file__ to the\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# script path in ScriptRunner.\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m abs_main_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(__main__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(abs_main_path\u001b[38;5;241m.\u001b[39mparent)\n",
      "\u001b[0;31mInternalHashError\u001b[0m: module '__main__' has no attribute '__file__'\n\nWhile caching the body of `load_data()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function load_data at 0x14f294540>\n```\n\nPlease see the `hash_funcs` [documentation](https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            "
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# CSV 파일 경로\n",
    "CSV_FILE_PATH = 'ticker_data.csv'\n",
    "\n",
    "# 데이터 로드\n",
    "@st.cache\n",
    "def load_data():\n",
    "    return pd.read_csv(CSV_FILE_PATH)\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "# Streamlit 앱 제목\n",
    "st.title('SCHD ETF Companies by Sector')\n",
    "\n",
    "# 데이터 미리보기\n",
    "st.subheader('Data Preview')\n",
    "st.write(df.head())\n",
    "\n",
    "# 트리맵 시각화\n",
    "fig = px.treemap(df, \n",
    "                 path=['Sector', 'Name'], \n",
    "                 values='MarketCap',\n",
    "                 title='SCHD ETF Companies Treemap by Sector')\n",
    "\n",
    "st.plotly_chart(fig)\n",
    "\n",
    "#\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 배당주와 비배당주의 티커 리스트\n",
    "dividend_stocks = ['AAPL', 'MSFT', 'KO']  # 예시: 배당주 티커\n",
    "non_dividend_stocks = ['GOOGL', 'AMZN', 'TSLA']  # 예시: 비배당주 티커\n",
    "\n",
    "# 데이터 수집 함수\n",
    "def get_stock_data(tickers, start_date, end_date):\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        df = stock.history(start=start_date, end=end_date, actions=True)\n",
    "        df['Ticker'] = ticker\n",
    "        data[ticker] = df\n",
    "    return pd.concat(data.values())\n",
    "\n",
    "# 데이터 가져오기\n",
    "start_date = '1984-01-01'\n",
    "end_date = '2024-07-01'\n",
    "dividend_data = get_stock_data(dividend_stocks, start_date, end_date)\n",
    "non_dividend_data = get_stock_data(non_dividend_stocks, start_date, end_date)\n",
    "\n",
    "# 배당금 포함된 데이터 처리\n",
    "def calculate_total_return(df):\n",
    "    df['Dividend'] = df['Dividends']\n",
    "    df['Total Return'] = (df['Close'] + df['Dividend']) / df['Close'].shift(1) - 1\n",
    "    return df\n",
    "\n",
    "dividend_data = calculate_total_return(dividend_data)\n",
    "non_dividend_data = calculate_total_return(non_dividend_data)\n",
    "\n",
    "# Streamlit 애플리케이션\n",
    "st.title('Dividend vs Non-Dividend Stock Total Return Comparison')\n",
    "\n",
    "# 그래프\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 배당주 라인 플로팅\n",
    "for ticker in dividend_stocks:\n",
    "    data = dividend_data[dividend_data['Ticker'] == ticker]\n",
    "    ax.plot(data.index, data['Total Return'], alpha=0.6, label=f'Dividend {ticker}')\n",
    "\n",
    "# 비배당주 라인 플로팅\n",
    "for ticker in non_dividend_stocks:\n",
    "    data = non_dividend_data[non_dividend_data['Ticker'] == ticker]\n",
    "    ax.plot(data.index, data['Total Return'], alpha=0.6, label=f'Non-Dividend {ticker}')\n",
    "\n",
    "# 이상치 제거를 위한 y축 범위 설정\n",
    "ax.set_ylim(-0.2, 0.2)\n",
    "\n",
    "# 그래프 제목 및 레이블 설정\n",
    "ax.set_title('Total Return Comparison')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Total Return')\n",
    "ax.legend()\n",
    "\n",
    "# 그래프 출력\n",
    "st.pyplot(fig)\n",
    "\n",
    "#\n",
    "#\n",
    "\n",
    "# 배당주와 비배당주의 평균 수익률 계산\n",
    "def calculate_group_average(df, tickers):\n",
    "    df_group = df[df['Ticker'].isin(tickers)]\n",
    "    avg_return = df_group.groupby(df_group.index)['Total Return'].mean()\n",
    "    return avg_return\n",
    "\n",
    "# 평균 수익률 계산\n",
    "dividend_avg_return = calculate_group_average(dividend_data, dividend_stocks)\n",
    "non_dividend_avg_return = calculate_group_average(non_dividend_data, non_dividend_stocks)\n",
    "\n",
    "# Streamlit 애플리케이션\n",
    "st.title('Average Total Return Comparison: Dividend vs Non-Dividend Stocks')\n",
    "\n",
    "# 그래프\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 평균 배당주 수익률 라인 플로팅\n",
    "ax.plot(dividend_avg_return.index, dividend_avg_return, alpha=0.6, label='Average Dividend Stocks')\n",
    "# 평균 비배당주 수익률 라인 플로팅\n",
    "ax.plot(non_dividend_avg_return.index, non_dividend_avg_return, alpha=0.6, label='Average Non-Dividend Stocks')\n",
    "\n",
    "# y축 범위 설정\n",
    "ax.set_ylim(-0.05, 0.05)\n",
    "\n",
    "# 그래프 제목 및 레이블 설정\n",
    "ax.set_title('Average Total Return Comparison')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Total Return')\n",
    "ax.legend()\n",
    "\n",
    "# 그래프 출력\n",
    "st.pyplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eeebbb-d1b1-4e37-b2a7-1ee207e53d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
